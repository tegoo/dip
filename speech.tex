\documentclass[14pt]{extarticle}

%\usepackage[T2A]{fontenc}               % fonts
\usepackage[utf8x]{inputenc}             % UTF-8
\usepackage[english,russian]{babel}     % russian
\usepackage{cmap}                       % russian search in pdf

\usepackage[a4paper, left=1cm, right=1cm, top=1cm, bottom=1cm]{geometry}   % pagesize
\usepackage{indentfirst}

\usepackage{amsmath}            % math
\usepackage{amsfonts}           % math fonts
\usepackage{amssymb}            % math symb

\begin{document}

\section{Титул}
Здравствуйте, уважаемая аттистационная комиссия. 
Представляю вам мою дипломную работу.


\section{Задача предсинтаксического аннотироания тектса}

Задача предсинтаксического аннотирования текста является первой фазой автоматической обработки текста на естественном языке. 

Задачу можно определить как разбиение последовательности символов на токены. Токены могут представлять собой словоформы, цифровые комплексы, знаки пунктуации.

Для найденных токенов могут быть установлены значения каких-либо атрибутов, например список граммем. 

\section{Существующие подходы}
Общепринятого подхода нет. Существуют подходы, основанные на использовании правил, задающих границы токенов, подходы основанные на словарном поиске и эвристике. Также возможно применение методов машинного обучения. 

К модулю предсинтаксического аннотирования текста выдвигаются такие требования, как
\begin{enumerate}
	\item 
	Разметка текста, содержащего дефекты;
	\item
	Одновременная работа с несколькими языками;
	\item
	Представление результата в виде ссылок на записи морфологического словаря.
\end{enumerate}

Дефекты в словоформах могут представлять собой орфографические ошибки и отсутствующие или, наоборот, лишние разделительные символы. В случаях наличия таких дефектов модуль должен выполнять предварительную коррекцию.

Существующих решений, удовлетворяющих всем требования в открытом доступе нет.

\section{Цель}
Разработать подход к предсинтаксическому аннотрованию текста, соответствующий указанным требованиям.

\section{Разработанный подход}
В работе предлагается подход к предсинтаксическому аннотированию текста на естественном языке. Предлагаемый подход состоит из двух фаз: фазы разметки текста и фазы словарного поиска. Первая фаза введена для выполнения предварительной разметки текста. Учет и коррекция дефектов в словоформах достигается введением второй фазы разметки.

\section{Фаза разметки текста}
На фазе разметки текста решается задача графематического анализа текста, представляющего собой последовтаельность символов пунктуации и символов алфавита естественного языка. Результатом является последовательность найденных токенов. На данной фазе используется Скрытая Марковская Модель.

\section{Скрытая Марковская Модель (СММ)}

Скрытая марковская модель представляет собой вероятностную модель. Это обучаемый стохастический конечный автомат. 

Модель объединяет в себе два стохастических процесса. Первый процесс представляет собой переходы между состояними, скрытыми от наблюдателя. Второй процесс представляет собой пояление некоторый событий, которые известны наблюдателю. Распределения вероятностей появления этих событий зависят от скрытого состояния, в котором находится система.

Существуют три базовые проблемы Скрытой марковской модели.
\begin{enumerate}
	\item 
	проблема оценки (заключается в определении вероятности появления некоторой последовательности событий)
	\item
	проблема обучения (заключается в максимизации оценки на некотром множестве последовательностей, называемом тренировочным множеством. максимизация достигается подбором параметров мадели)
	\item
	проблема декодирования (заключается в предсказании последовательности скрытых состояний по последовательности наблюдений)
\end{enumerate}

Применительно к задаче разметки текста на естественном языке скрытый процесс представляет собой появление границ токенов. Наблюдаемый процесс - это входная последовательность символов, представляющая собой текст на естественном языке.

Может быть выделено три скрытых состояния:
\begin{enumerate}
	\item 
	граница токена
	\item
	внутри токена
	\item
	вне токена
\end{enumerate}

Используется метод обучения с учителем, для которого было подготовлено обучающее множество.

\section{Обучающее множество}
Обучающее множество представляет собой множество размеченных строк текста. Оно было получена на основе Национального корпуса русского языка, который доступен для некомерческого использования.

В ходе исследования было проведено тестирование с целью составления представления о том, какой объем обучающего множества необходим, для достижения малой доли ошибок разметки.

\section{Фаза словарного поиска}
Вторая фаза разметки использует морфологический словарь.
Сначала производится прямой поиск словоформы. 
Если словоформа не найдена, то производится нечеткий поиск, основанный на вычислении редакционного расстояния.
В результате нечеткого поиска может быть получено несколько вариантов токенизации. В таком случае производится ранжирование результатов.

\section{Графовый словарь}
В разработанном подходе используется словарь, имеющий графовую структуру.  Данный словарь объединяет в себе морфологический словарь и семантическую сеть. В рамках графовой структуры словаря определены узлы трех типов: семантические узлы, узлы лексем и узлы словоформ. Такая структура словаря позволяет найти связь между словоформой и связанным с ней смыслом. 

Для оптимизации работы со словарем строится префиксное дерево поиска, узлы которого сссылаются на соответствующие узлы словоформ графового словаря.


\section{Алгоритм нечеткого поиска}
Для реализации нечеткого поиска используется редакционное расстояние Левенштейна.
В рамках нечеткого поиска формируется список путей прохождения по дереву. На каждом шаге поиска каждый имеющийся путь заменяется множеством путей, полученных дополнением дочерних узлов. Пути, для которых расстояние Левенштейна превышает некоторое пороговое значение, отбрасываются.

\section{Ранжирование}
В результате работы алгоритма нечеткого поиска может быть получено несколько вариантов разметки. В таком случае производится ранжирование списка результатов в соответствии с критерием, учитывающим степень совпадения и вероятность последовательности словоформ в соответствии с моделью n-грамм.

\begin{align*}
	&W = w_1w_2w_3...w_n  \text{-- вариант токенизации} \\
	&w_i \text{-- найденная словоформа} \\
	&w_{dict_i} \text{-- словоформа из словаря} \\
	&dist(S_1, S_2) \text{-- редакционное расстояние между строками } S_1 \text{ и } S_2\\
	&k(W) = k_{match}(W) \cdot k_{prob}(W) \\
	&\text{Критерий совпадения:} \\
	&k_{match} = 1 - \frac{\displaystyle\sum_{j} dist(w_j,w_{dict_j}) }{\displaystyle\sum_{j} max(|w_j|,|w_{dict_j}|) } \\
	&\text{Вероятностный критерий} \\
	&\text{(на основе модели n-грамм): } \\
	&k_{prob} = \prod_{j}P(w_j|w_{j-1})
\end{align*}



\(W_1\) считается лучше \(W_2\), если \(k(W_1) > k(W_2)\).


\section{Результаты исследования}

Найден подход к предсинтаксическому аннотированию текста, соответствующий поставленным требованиям.

Предложен двухэтапный алгоритм, построенный на основе использования Скрытой марковской модели и нечеткого поиска по морфологическому словарю.

Разработан программный модуль, выполняющий предсинтаксическое аннотирование текста на естественном языке

\end{document}